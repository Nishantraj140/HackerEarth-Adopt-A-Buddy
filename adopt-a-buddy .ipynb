{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skmultilearn.problem_transform import BinaryRelevance,ClassifierChain,LabelPowerset\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv('../input/dataset/train.csv')\ndf_test=pd.read_csv('../input/dataset/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(df_train.head())\nprint(df_train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train['pet_category'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=df_train['pet_category'].values\nprint(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train['condition'].unique())\nprint(df_train['color_type'].unique())\nprint(df_train['breed_category'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train['length(m)'].unique())\nprint(df_train['height(cm)'].unique())\nprint(df_train['X1'].unique())\nprint(df_train['X2'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(df_train['length(m)'].isna().sum())\nprint(df_train['height(cm)'].isna().sum())\nprint(df_train['X1'].isna().sum())\nprint(df_train['X2'].isna().sum())\n\nprint(df_train['condition'].isna().sum())\nprint(df_train['color_type'].isna().sum())\nprint(df_train['breed_category'].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(df_test['length(m)'].isna().sum())\nprint(df_test['height(cm)'].isna().sum())\nprint(df_test['X1'].isna().sum())\nprint(df_test['X2'].isna().sum())\n\nprint(df_test['condition'].isna().sum())\nprint(df_test['color_type'].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(df_train.groupby(['condition']).size())\n\nprint(df_train[df_train['condition'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train[df_train['condition'].isnull()]['breed_category'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['breed_category']==2].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['condition']=df_train['condition'].replace(np.nan,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['condition']=df_test['condition'].replace(np.nan,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.groupby(['condition']).size())\n\nprint(df_train[df_train['condition'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_train['diff_days']=np.abs((pd.to_datetime(df_train['listing_date'].values)-pd.to_datetime(df_train['issue_date'].values)).days)\n\nprint(df_train['diff_days'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_test['diff_days']=(pd.to_datetime(df_test['listing_date'].values)-pd.to_datetime(df_test['issue_date'].values)).days\n\nprint(df_test['diff_days'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train['issue_date'][5], \" \", df_train['listing_date'][5], \" \",df_train['diff_days'][5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_new=df_train.drop(columns=['issue_date','listing_date'])\n\nprint(df_train_new.head())\nprint(df_train_new.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_test_new=df_test.drop(columns=['issue_date','listing_date'])\n\nprint(df_test_new.head())\nprint(df_test_new.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\ndf_train_new[\"color_type_code\"] = lb_make.fit_transform(df_train_new[\"color_type\"])\ndf_train_new[[\"color_type\", \"color_type_code\"]].head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_test_new[\"color_type_code\"] = lb_make.transform(df_test_new[\"color_type\"])\ndf_test_new[[\"color_type\", \"color_type_code\"]].head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_new['color_type_code'].unique()\n\ndf_train_new=df_train_new.drop(columns=['color_type'])\n\nprint(df_train_new.head(25))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_new['color_type_code'].unique()\n\ndf_test_new=df_test_new.drop(columns=['color_type'])\n\nprint(df_test_new.head(25))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train_new.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew \nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the distribution \nsns.distplot(df_train_new['length(m)'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"Length\")\nax.set(title=\"Length distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\nprint(\"skew value: \", skew(df_train_new['length(m)']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew \nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the distribution \nsns.distplot(df_train_new['height(cm)'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"Height\")\nax.set(title=\"Height distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\nprint(\"skew value: \", skew(df_train_new['height(cm)']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew \nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the distribution \nsns.distplot(df_train_new['X1'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"X1\")\nax.set(title=\"X1 distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\nprint(\"skew value: \", skew(df_train_new['X1']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew \nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the distribution \nsns.distplot(df_train_new['X2'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"X2\")\nax.set(title=\"X2 distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\nprint(\"skew value: \", skew(df_train_new['X2']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew \nX1_trans=np.log(1+df_train_new['X1'].values)\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the distribution \nsns.distplot(X1_trans, color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"X1\")\nax.set(title=\"X1 distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\nprint(\"skew value: \", skew(X1_trans))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew \nX1_trans_test=np.log(1+df_test_new['X1'].values)\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the distribution \nsns.distplot(X1_trans, color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"X1\")\nax.set(title=\"X1 distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\nprint(\"skew value: \", skew(X1_trans_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_norm=df_train_new\ndf_train_norm['X1']=X1_trans\n\ndf_test_norm=df_test_new\ndf_test_norm['X1']=X1_trans_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_norm['Low_Length']=np.where(df_train_norm['length(m)']<=0.3,1,0)\ndf_train_norm['Medium_Length']=np.where((df_train_norm['length(m)']>0.3) & (df_train_norm['length(m)']<=0.6),1,0)\ndf_train_norm['High_Length']=np.where(df_train_norm['length(m)']>0.6,1,0)\n\ndf_test_norm['Low_Length']=np.where(df_test_norm['length(m)']<=0.3,1,0)\ndf_test_norm['Medium_Length']=np.where((df_test_norm['length(m)']>0.3) & (df_test_norm['length(m)']<=0.6),1,0)\ndf_test_norm['High_Length']=np.where(df_test_norm['length(m)']>0.6,1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(df_train_norm.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\nY=df_train_norm['pet_category'].values\nX=df_train_norm.drop(columns=['pet_category','pet_id','breed_category'])\n\nX_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nmodel=XGBClassifier()\nmodel.fit(X_train,y_train)\ny_pred=model.predict(X_test)\nprint(f1_score(y_pred,y_test,average='weighted'))\nprint(accuracy_score(y_pred,y_test))\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nY=df_train_norm['breed_category'].values\nX=df_train_norm.drop(columns=['pet_category','pet_id','breed_category'])\n\nX_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nmodel2=XGBClassifier()\nmodel2.fit(X_train,y_train)\ny_pred=model2.predict(X_test)\nprint(f1_score(y_pred,y_test,average='weighted'))\nprint(accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Y_test_fin=df_test_new['pet_category'].values\nidx=df_test_norm['pet_id'].values\nX_test_fin=df_test_norm.drop(columns=['pet_id'])\n\n\ny_pred_fin=model.predict(X_test_fin)\n\n\nfrom sklearn.model_selection import train_test_split\n\n#Y_test_fin=df_test_new['pet_category'].values\nidx=df_test_norm['pet_id'].values\nX_test_fin=df_test_norm.drop(columns=['pet_id'])\n\n\ny_pred_fin2=model2.predict(X_test_fin)\n\n\ndf_sub = pd.DataFrame({'pet_id': idx,\n                   'breed_category': y_pred_fin2,\n                   'pet_category': y_pred_fin})\ndf_sub.to_csv('submit.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nY=df_train_norm['pet_category'].values\nX=df_train_norm.drop(columns=['pet_category','pet_id','breed_category'])\n\nX_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nmodel=XGBClassifier(silent=False, \n                      scale_pos_weight=1,\n                      learning_rate=0.4,  \n                      colsample_bytree = 0.4,\n                      subsample = 0.8,\n                      objective='binary:logistic', \n                      n_estimators=1000, \n                      reg_alpha = 0.3,\n                      max_depth=4, \n                      gamma=4)\n\nmodel.fit(X_train,y_train)\ny_pred=model.predict(X_test)\nprint(f1_score(y_pred,y_test,average='weighted'))\nprint(accuracy_score(y_pred,y_test))\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nY=df_train_norm['breed_category'].values\nX=df_train_norm.drop(columns=['pet_category','pet_id','breed_category'])\n\nX_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nmodel2=XGBClassifier(silent=False, \n                      scale_pos_weight=1,\n                      learning_rate=0.4,  \n                      colsample_bytree = 0.4,\n                      subsample = 0.8,\n                      objective='binary:logistic', \n                      n_estimators=1000, \n                      reg_alpha = 0.3,\n                      max_depth=4, \n                      gamma=4)\nmodel2.fit(X_train,y_train)\ny_pred=model2.predict(X_test)\nprint(f1_score(y_pred,y_test,average='weighted'))\nprint(accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Y_test_fin=df_test_new['pet_category'].values\nidx=df_test_norm['pet_id'].values\nX_test_fin=df_test_norm.drop(columns=['pet_id'])\n\n\ny_pred_fin=model.predict(X_test_fin)\n\n\nfrom sklearn.model_selection import train_test_split\n\n#Y_test_fin=df_test_new['pet_category'].values\nidx=df_test_norm['pet_id'].values\nX_test_fin=df_test_norm.drop(columns=['pet_id'])\n\n\ny_pred_fin2=model2.predict(X_test_fin)\n\n\ndf_sub = pd.DataFrame({'pet_id': idx,\n                   'breed_category': y_pred_fin2,\n                   'pet_category': y_pred_fin})\ndf_sub.to_csv('submit.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nY=df_train_norm['pet_category'].values\nX=df_train_norm.drop(columns=['pet_category','pet_id','breed_category'])\n'''\nX_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n'''\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nmodelx=XGBClassifier(silent=False, \n                      scale_pos_weight=1,\n                      learning_rate=0.4,  \n                      colsample_bytree = 0.4,\n                      subsample = 0.8,\n                      objective='binary:logistic', \n                      n_estimators=1000, \n                      reg_alpha = 0.3,\n                      max_depth=4, \n                      gamma=4)\n\nmodelx.fit(X,Y)\n\n'''\ny_pred=model.predict(X_test)\nprint(f1_score(y_pred,y_test,average='weighted'))\nprint(accuracy_score(y_pred,y_test))\n\n'''\n\nfrom sklearn.model_selection import train_test_split\n\nY=df_train_norm['breed_category'].values\nX=df_train_norm.drop(columns=['pet_category','pet_id','breed_category'])\n'''\nX_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n'''\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nmodelx2=XGBClassifier(silent=False, \n                      scale_pos_weight=1,\n                      learning_rate=0.4,  \n                      colsample_bytree = 0.4,\n                      subsample = 0.8,\n                      objective='binary:logistic', \n                      n_estimators=1000, \n                      reg_alpha = 0.3,\n                      max_depth=4, \n                      gamma=4)\nmodelx2.fit(X,Y)\n'''\ny_pred=model2.predict(X_test)\nprint(f1_score(y_pred,y_test,average='weighted'))\nprint(accuracy_score(y_pred,y_test))\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Y_test_fin=df_test_new['pet_category'].values\nidx=df_test_norm['pet_id'].values\nX_test_fin=df_test_norm.drop(columns=['pet_id'])\n\n\ny_pred_fin=modelx.predict(X_test_fin)\n\n\nfrom sklearn.model_selection import train_test_split\n\n#Y_test_fin=df_test_new['pet_category'].values\nidx=df_test_norm['pet_id'].values\nX_test_fin=df_test_norm.drop(columns=['pet_id'])\n\n\ny_pred_fin2=modelx2.predict(X_test_fin)\n\n\ndf_sub = pd.DataFrame({'pet_id': idx,\n                   'breed_category': y_pred_fin2,\n                   'pet_category': y_pred_fin})\ndf_sub.to_csv('submit.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}